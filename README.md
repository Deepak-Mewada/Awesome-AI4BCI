# Awesome-AI4BCI
AI, especially Deep Learning, has made breakthroughs in learning from Brain Signals, vital for both Brain Encoding and Decoding. Unlock the potential with this repository—a curated collection of resources and papers on Deep Learning Models for Brain-Computer Interfaces. Dive in to explore the future of brain-related AI advancements.

## Contents
- [Papers](#papers)
  - [Survey](#survey)
  - [Few-Shot Learning for BCIs](#FSL4BCI)
  - [Meta-Leanring for BCI](#MetaL4BCI)
  - [Equivariant Networks](#equivariant-networks)
  - [Transformer for BCI](#transformer4BCI)
  - [Materials Generation](#materials-generation)


# Papers

## Survey
**Paper Title** [[Paper](https://www.)] <br>
<sub><em>*Authors* </em>
journal & Year. </sub>

**2020 International brain–computer interface competition: A review** [[Paper](https://www.frontiersin.org/articles/10.3389/fnhum.2022.898300/full)] <br>
<sub><em>Ji-Hoon Jeong et.al china;</em> Frontiers of Human Neuroscience & 2022. <sub>

## FSL4BCI

### MI-BCI

**Decoding Multi-Brain Motor Imagery from EEG Using Coupling Feature Extraction and Few-Shot Learning** [[Paper](https://europepmc.org/article/med/37995161#full-text-links)] <br>
<sub> <em>Li Zhu, Youyang Liu, Riheng Liu, Yong Peng, Jianting Cao,Junhua Li, and Wanzeng Kong, Senior Member, IEEE*  <br>
 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING & 23/11/2023.</em><sub> 

### non MI-BCI
**EEG-Fest: Few-shot based Attention Network for Driver's DrowsinessEstimation with EEG Signals** [[Paper](https://iopscience.iop.org/article/10.1088/2057-1976/ad0f3f/pdf)] <br>
<sub> *Ning Ding, Ce Zhang and Azim Eskandarian, Mechanical Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA* <br>
Biomedical Physics & Engineering  28/11/2023. <sub>
<details>
<summary>Main points of the Papers</summary>
This is the hidden content that will be shown or hidden based on user interaction.
</details>


**Emotion Recognition from Few-Channel EEG Signals by Integrating Deep Feature Aggregation and Transfer Learning** [[Paper](https://www.computer.org/csdl/journal/ta/5555/01/10328701/1SkODjGeYz6)] <br>
<sub>*Fang Liu et.al, BNRist, the Department of Computer Science and Technology, Tsinghua University, China  <br>
IEEE Transactions on Affective Computing & 21/11/2023. <sub>

## MetaLearning4BCI

**Meta-Learning for Subject Adaptation in Low-Data Environments for EEG-Based Motor Imagery Brain-Computer Interfaces** [[Paper](https://openreview.net/pdf?id=7QqlQW9hJ8J)]
<sub><em>Arnav Pati, Deepak Mewada, Debasis Samanta </em>
ICLR & MArch,2023. </sub>


**META-EEG: Meta-learning-based class-relevant EEG representation learning for zero-calibration brain–computer interfaces** [[Paper](https://www.sciencedirect.com/science/article/pii/S0957417423024880?ef=pdf_download&fr=RR-2&rr=82d45a910f158a02)] <br>
<sub><em>Ji-Wung Han1
, Soyeon Bak1
, Jun-Mo Kim, WooHyeok Choi, Dong-Hee Shin, Young-Han Son,
Tae-Eui Kam ∗
Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea; </em>
Expert Systems With Applications & 10/10/2023. </sub>

## Transformer4BCI

## Variability in EEG-BCI
**Discrepancy between inter- and intra-subject variability in EEG-based motor imagery brain-computer interface: Evidence from multiple perspectives** [[Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9968845/pdf/fnins-17-1122661.pdf)] <br>
<sub> <em>Gan Huang,Zhiheng Zhao1,Shaorong Zhang,Zhenxing Hu1,Jiaming Fan1,Meisong Fu1,Jiale Chen1,Yaqiong Xiao4, Jun Wang5 and Guo Dan; China<br>
Frontiers in Neuroscience & 13/02/2023. </em><sub> 

**Reducing the Subject Variability of EEG Signals with Adversarial Domain Generalization** [[Paper](https://weilongzheng.github.io/publication/ma2019reducing/ma2019reducing.pdf)] <br>
<sub> <em>Bo-Qun Ma1, He Li1, Wei-Long Zheng2, and Bao-Liang Lu1, China <br>
Springer Nature & 2019. </em><sub> 

**MITIGATING INTER-SUBJECT BRAIN SIGNAL VARIABILITY FOR EEG-BASED DRIVER FATIGUE STATE CLASSIFICATION** [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9414613&tag=1)] <br> 
<sub><em>Sunhee Hwang, Sungho Park, Dohyung Kim, Jewook Lee1 and Hyeran Byun <br>
ICASSP & 2021 </em></sub>

**EEG variability: Task-driven or subject-driven signal of interest?** [[Paper](https://www.sciencedirect.com/science/article/pii/S105381192200163X)] <br>
<sub><em>Erin Gibson a, Nancy J. Lobaugh c d, Steve Joordens b, Anthony R. McIntosh,Univ of Totanto Canada;</em> Elsevier & 15 MAy 2022 </sub>

**Paper Title** [[Paper](https://www.)] <br>
<sub><em>*Authors* </em>
journal & Year. </sub>

**Paper Title** [[Paper](https://www.)] <br>
<sub><em>*Authors* </em>
journal & Year. </sub>

**Paper Title** [[Paper](https://www.)] <br>
<sub><em>*Authors* </em>
journal & Year. </sub>

**Paper Title** [[Paper](https://www.)] <br>
<sub><em>*Authors* </em>
journal & Year. </sub>

**Paper Title** [[Paper](https://www.)] <br>
<sub><em>*Authors* </em>
journal & Year. </sub>

## Generalised Neural Decoder
**Generalized neural decoders for transfer learning across participants and recording modalities** [[Paper](https://iopscience.iop.org/article/10.1088/1741-2552/abda0b/pdf)] <br>
<sub><em>Steven M Peterson1,2, Zoe Steine-Hanson3, Nathan Davis3
, Rajesh P N Rao,and Bingni W Brunton | </em>
journal of Neural Engineering & 2020. </sub>



# General AI papers
**Meta-Transfer Learning for Few-Shot Learning** [[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.pdf)] <br>
<sub><em>Qianru Sun1,3∗ Yaoyao Liu2∗ Tat-Seng Chua1 Bernt Schiele3</em>
CVPR & Year. </sub>

# Resources for Students
- [[Research and Writing Tips from SJN University](https://vision.sjtu.edu.cn/writing.html) ]
- [[Notes on writing Fredo Durand, MIT CSAIL](https://people.csail.mit.edu/fredo/PUBLI/writing.pdf)]
- [[Write Good Papers Frédo Durand](https://people.csail.mit.edu/fredo/FredoGoodWriting.pdf)]
- [[Resources for Students & Scholars by Frédo Durand; MIT ](https://people.csail.mit.edu/fredo/student.html)] 
-

----
---
# My Project

This is a description of my project.

<details>
<summary>Click to expand</summary>
<details>
<summary>Click to expand!</summary>

This is the hidden content that will be shown or hidden based on user interaction.
</details>
## Installation

Instructions for installing the project.

## Usage

Information on how to use the project.

## Contributing

Guidelines for contributing to the project.

</details>
<span style="font-size: smaller;">This text will have a smaller font size.</span>

# My Project

This is a description of my project.

<small>This text will have a smaller font size.</small>
# My Project

This is a description of my project.

## Features

- Feature 1
- Feature 2
- Feature 3

<small>This text will have a smaller font size.</small>

<span style="font-size: x-small;">This text will have an even smaller font size.</span>

<span style="font-size: 0.1em;">This text will have a font size of 80% of the parent element's font size.</span>

# My Project

This is a description of my project.

<span style="font-size: 12px;">This text will have a font size of 12 pixels.</span>

<span style="font-size: 0.8em;">This text will have a font size of 80% of the parent element's font size.</span>

<h6>hello</h6>
<h5>hello</h7>
<h4>hello</h8>

<p style="font-size:1px;">This text will be smaller</p>

> [!NOTE]
> Highlights information that users should take into account, even when skimming.

> [!TIP]
> Optional information to help a user be more successful.

> [!IMPORTANT]
> Crucial information necessary for users to succeed.

> [!WARNING]
> Critical content demanding immediate user attention due to potential risks.

> [!CAUTION]
> Negative potential consequences of an action.
<p style="font-size: 1px;">This is a paragraph with a smaller font size.</p>

